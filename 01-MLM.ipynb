{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\r\n",
    "# transformers: https://huggingface.co/transformers/quicktour.html\r\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 01-instantiate a tokenizer from pretrained Bert tokenizer model\r\n",
    "# 02-instantiate a model from pretrained Bert model\r\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\r\n",
    "\r\n",
    "text = (\"After Abraham Lincoln won the November 1860 presidential \"\r\n",
    "        \"election on an anti-slavery platform, an initial seven \"\r\n",
    "        \"slave states declared their secession from the country \"\r\n",
    "        \"to form the Confederacy. War broke out in April 1861 \"\r\n",
    "        \"when secessionist forces attacked Fort Sumter in South \"\r\n",
    "        \"Carolina, just over a month after Lincoln's \"\r\n",
    "        \"inauguration.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 440M/440M [01:37<00:00, 4.49MB/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 03-tonkenizer the text into tokens\r\n",
    "inputs = tokenizer(text, return_tensors='pt')\r\n",
    "inputs.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "inputs.input_ids"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()\r\n",
    "inputs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102]])}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# 04-rand a list of numbers with tokens' shape \r\n",
    "rand = torch.rand(inputs.input_ids.shape)\r\n",
    "rand"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.4582, 0.2403, 0.4976, 0.5111, 0.3772, 0.9404, 0.5976, 0.6746, 0.8828,\n",
       "         0.3921, 0.0115, 0.8169, 0.7122, 0.1853, 0.0569, 0.5207, 0.7042, 0.4694,\n",
       "         0.9005, 0.2028, 0.9583, 0.2316, 0.4543, 0.4832, 0.4607, 0.1164, 0.3863,\n",
       "         0.8290, 0.5301, 0.0667, 0.4867, 0.3269, 0.9129, 0.7592, 0.3803, 0.4642,\n",
       "         0.5184, 0.4311, 0.2716, 0.4112, 0.8755, 0.0392, 0.1929, 0.2689, 0.9666,\n",
       "         0.4721, 0.7022, 0.4101, 0.7547, 0.1365, 0.8996, 0.9065, 0.9952, 0.7201,\n",
       "         0.2398, 0.2588, 0.9122, 0.3552, 0.2274, 0.2377, 0.2795, 0.1987]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# 05-select 15% of rand list and tag with True\r\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)\r\n",
    "mask_arr"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False,  True, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True, False, False, False,  True,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True, False, False, False, False, False, False, False,  True,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# 06-transfmer the True tag into token ids\r\n",
    "selection = torch.flatten(mask_arr[0].nonzero()).tolist()\r\n",
    "selection"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[10, 14, 25, 29, 41, 49]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# 07-change the token number into Mask id which is 103\r\n",
    "inputs.input_ids[0,selection] = 103\r\n",
    "inputs.input_ids"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[  101,   103,  8181,  5367,  2180,   103,  2281,   103,  4883,  2602,\n",
       "           103,  2019,  3424,  1011,   103,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,   103,  1996,  2406,  2000,   103,\n",
       "           103, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,   103,   103,  4457,  3481,  7680,  3334,  1999,  2148,   103,\n",
       "           103,  2074,  2058,  1037,  3204,   103,  5367,  1005,  1055, 17331,\n",
       "           103,   102]])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 08-give inputs into model and to get the outputs\r\n",
    "ouputs = model(**inputs)\r\n",
    "ouputs.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "ouputs.loss"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.8998, grad_fn=<NllLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(ouputs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MaskedLMOutput(loss=tensor(0.8998, grad_fn=<NllLossBackward>), logits=tensor([[[ -7.1377,  -7.0650,  -7.1165,  ...,  -6.3372,  -6.2205,  -4.4824],\n",
      "         [ -5.5711,  -5.5090,  -5.4517,  ...,  -4.6035,  -5.3964,  -5.0494],\n",
      "         [ -7.6065,  -7.9540,  -7.1785,  ...,  -6.9689,  -5.8796,  -8.0458],\n",
      "         ...,\n",
      "         [ -4.2649,  -4.4033,  -4.2061,  ...,  -3.3423,  -2.7477,  -7.5108],\n",
      "         [ -8.3504,  -8.1620,  -8.5493,  ...,  -7.4944,  -8.7737,  -3.2763],\n",
      "         [-12.8792, -12.9911, -13.0218,  ...,  -9.3398,  -9.9814,  -8.6422]]],\n",
      "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "predictions = torch.nn.functional.softmax(ouputs.logits, dim=-1)\r\n",
    "print(predictions)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[3.1191e-07, 3.3542e-07, 3.1858e-07,  ..., 6.9453e-07,\n",
      "          7.8051e-07, 4.4381e-06],\n",
      "         [3.6587e-09, 3.8931e-09, 4.1230e-09,  ..., 9.6283e-09,\n",
      "          4.3573e-09, 6.1648e-09],\n",
      "         [7.9557e-11, 5.6205e-11, 1.2206e-10,  ..., 1.5052e-10,\n",
      "          4.4737e-10, 5.1274e-11],\n",
      "         ...,\n",
      "         [5.2250e-12, 4.5498e-12, 5.5414e-12,  ..., 1.3146e-11,\n",
      "          2.3825e-11, 2.0342e-13],\n",
      "         [3.5026e-13, 4.2289e-13, 2.8708e-13,  ..., 8.2445e-13,\n",
      "          2.2940e-13, 5.5984e-11],\n",
      "         [2.9094e-13, 2.6014e-13, 2.5228e-13,  ..., 1.0022e-11,\n",
      "          5.2761e-12, 2.0134e-11]]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('pDL': conda)"
  },
  "interpreter": {
   "hash": "1c0e05ce53746a51582d81d6493e921a5fc2be3a37559f7311fb011379659f5e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}